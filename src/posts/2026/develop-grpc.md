---
title: Изобретая grpc
author: kafkiansky
date: 2026-02-23
tags:
  - php
  - grpc
draft: false
prev:
  title: Изобретая protobuf
  url: 2026/develop-protobuf
---

Хотя `grpc` тесно ассоциирован с `protobuf` как часть одного фреймворка, эта связь не настолько сильная, чтобы на месте `protobuf` нельзя было использовать `msgpack`, упомянутый в прошлой статье `avro` или даже `json`. В отличие от `amqp`, протоколов `cassandra`, `kafka` и некоторых других систем, которые, на самом деле, объединяют в себе протоколы общения и сериализации, `grpc` как транспорт оборачивает сообщения, сериализованные в любом формате, в собственный бинарный протокол.

При этом и самостоятельным транспортом `grpc` назвать тоже трудно — он работает на `http/2`, используя в качестве тела запроса всего один бинарный фрейм, куда входят флаг, указывающий, сжато сообщение, например в `gzip`, или нет, размер сообщения и само сообщение. Ни больше ни меньше, `grpc` — это фреймворк, или, если еще точнее, спецификация к фреймворку, позволяющая построить альтернативную классическому `http` экосистему на любом языке программирования. 

Хотя может показаться, что использование `http` протокола не является преимуществом по сравнению с привычным для многих `openapi`, важно понимать, что `http/2`, хоть и считается идейным продолжителем[^1], на самом деле является совсем другим протоколом.

Если не говорить про `http/1`, главный недостаток которого — закрытие соединения после каждого запроса — исправил `http/1.1`, даже он не смог избавиться от всех родовых травм этого протокола. И текстовый формат, если вы подумали про него, — не самая большая из них. В конце концов, есть текстовые протоколы, вроде `nats` и `redis`, которые по производительности не уступают бинарным. Серьезной проблемой является синхронность этого протокола: нельзя отправить два запроса *параллельно*[^2] по одному соединению. Ради масштабирования приходится использовать пул соединений, который значительно дороже и ограниченнее мультиплексирования запросов через стримы, предлагаемых `http/2`. `grpc` не стал прятать `http/2`, а сделал его стримы — одно из главных преимуществ этого протокола — частью фреймворка, что доступно прямо в схеме определения сервисов. 

Чтобы понять преимущество стримов, надо знать, как работает `http/1.1`. Любой запрос внутри такого соединения блокирует целое соединение, пока на запрос не будет получен ответ. Так происходит из-за отсутствия какой-либо идентификации между запросами, что быстро их запутает, отправь мы следующий запрос. Вернее, отправить следующий запрос мы можем, особенно если использовать [http/1.1 pipelining](https://en.wikipedia.org/wiki/HTTP_pipelining), — который, впрочем, не снискал популярности, — однако этот запрос будет обработан сервером только после завершения текущего. Как бы то ни было, мы сталкивались с проблемой [head of line blocking](https://en.wikipedia.org/wiki/Head-of-line_blocking), которую были вынуждены решать открытием нового соединения. 

Решением этой проблемы являются стримы, которые где-то, например в `amqp`, называют каналами, где-то, например в `cassandra`, сессиями, а где-то как-то еще. Идея у них общая: каждый стрим получает некоторый уникальный[^3] идентификатор, который добавляется к каждому запросу внутри этого стрима. Все запросы внутри стрима упорядочены, как если бы это было классическое `http/1` соединение, но между стримами порядка быть не должно, потому что и клиент, и сервер сопоставляют запрос с ответом, используя их идентификаторы. Когда эти идентификаторы заканчиваются, то есть их, стримов, количество превысило число 2^31, соединение переоткрывается. Хотя это число является большим, только половину, а именно — нечетную, можно использовать для обычных запросов. Вторая, четная, половина нужна для реализации так называемого [server push](https://en.wikipedia.org/wiki/HTTP/2_Server_Push), о котором в этой статье я говорить не буду.

Стрим в `grpc` может быть использован как для унарных запросов, в случае с которыми стрим закрывается сразу после получения одного ответа от сервера, так и для потоковых запросов — тогда стрим может быть закрыт либо клиентом, либо сервером, либо любым из них в зависимости от типа стрима: клиентского, серверного или двунаправленного. Эти типы искусственно введены `grpc`, чтобы создать правильные ограничения при реализации определенных задач. По умолчанию же все `http/2` стримы являются двунаправленными.  

Важным дополнением в `http/2` являются трейлеры, которые имеют формат заголовков и отправляются после тела запроса. Поскольку стрим является продолжительным потоком сообщений, возникает необходимость каким-то образом его корректно завершить, передав окончательные статус выполнения и другую дополнительную информацию о состоянии стрима после его завершения. Раз заголовки были уже отправлены, нужен другой способ это сделать, и им являются трейлеры. Именно с помощью них `grpc` сервер отправляет заголовки `grpc-status` и `grpc-message` по окончании стрима.

Хотя `grpc` использует `http/2`, это проявляется не во всем. Так, в качестве статус-кода сервер всегда отправляет 200. Исключением является только единственный случай: если клиент в качестве `content-type` присылает что угодно, кроме `application/grpc`, сервер обязан вернуть 415-й код, потому что маловероятно, что специфические для `grpc` трейлеры клиент, приславший другой `content-type`, поймет. Все данные передаются только в теле запроса, включая различные идентификаторы, которые в обычном случае принято передавать в виде `path` параметров, и поэтому все запросы отправляются методом `POST`. Впрочем, на эти свойства вы все равно повлиять не можете: для вас все выглядит так, будто `grpc` использует собственный протокол общения. 

Чтобы договориться с сервером о формате сериализации входящих сообщений, клиент может добавить в заголовок `content-type` название формата через знак "`+`". Для `protobuf` заголовком будет `application/grpc+proto`. По умолчанию, как вы понимаете, и так будет `protobuf`, поэтому его передачу можно опустить. Если формат сериализации сервером не поддерживается, в качестве `grpc-status` будет возвращен код 12 (`UNIMPLEMENTED`)[^4]. То же самое будет при вызове несуществующего `rpc`. К слову, полное название `rpc`, которое передается как `path` в `http` протоколе, формируется из названия пакета, сервиса и имени `rpc` внутри этого сервиса. Например, для такой схемы именем будет `/queue.api.v1.QueueService/CreateQueue`:
```proto
syntax = "proto3";

package queue.api.v1;

service QueueService {
  rpc CreateQueue(...) returns (...);
}
```

Если имя пакета не указано, оно просто не используется. 

Поскольку каждое сообщение сериализуется в бинарный формат, в качестве которого обычно используется `protobuf`, оно хорошо поддается сжатию. Однако типичный для такой задачи заголовок `content-encoding` использовать нельзя, потому что он указывает на сериализацию всего тела сообщения, даже если оно отправляется частями, в то время как в `grpc` каждое сообщение сжимается отдельно, о чем [говорит](https://github.com/thesis-php/grpc/blob/0.1.x/src/Internal/Protocol/Frame.php#L29) первый байт фрейма. Поэтому в `grpc` для передачи алгоритмов сжатия используются заголовки `grpc-encoding`, отправляемый клиентом, и `grpc-accept-encoding`, отправляемый сервером. Несмотря на отправку заголовка `grpc-encoding`, сообщение по-прежнему может быть не сжато, о чем свидетельствует упомянутый байт сжатия. 

Хотя обычно клиент заранее знает алгоритмы сжатия, поддерживаемые сервером, поскольку они часто являются частью одного приложения, иногда клиент может выяснить алгоритмы после отправки первого сообщения, получив заголовок `grpc-accept-encoding`, чтобы все следующие сообщения отправлять уже сжатыми, именно поэтому байт сжатия устанавливается на уровне каждого сообщения, что позволяет адаптировать настройки стрима уже после его создания. Для унарных запросов это неактуально, потому что после получения ответа сжимать уже нечего.

---

[^1]: под продолжением идей я подразумеваю передачу метода, пути, заголовков и тела сообщения. 

[^2]: тут долго можно спорить, что называть параллелизмом при работе с сетью, потому что в конечном итоге все упирается в строго упорядоченный `tcp`, проблемы которого уже решает следующая версия `http` — `http/3`, работающий на `quic`. Я же больше подразумеваю параллелизм на стороне сервера, а не сокета, один медленный запрос к которому не заблокирует целое соединение. 

[^3]: в некоторых протоколах уникальный он только на то время, пока о нем не забыли клиент с сервером; после этого ранее использованные идентификаторы можно использовать опять. 

[^4]: этот и другой коды берутся из [этого енама](https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto#L32). Если вы обратите внимание, в комментариях к каждому коду описан соответствующий `http` код, от чего может сложиться впечатление, что они всегда отправляются в паре. Однако это не так: `http` код отправляется только при загадочном (особенно при использовании прокси) отсутствии заголовка `grpc-status`, и поэтому клиент может использовать классический заголовок в качестве замены.
