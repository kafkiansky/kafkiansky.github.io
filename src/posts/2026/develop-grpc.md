---
title: Изобретая grpc
author: kafkiansky
date: 2026-02-23
tags:
  - php
  - grpc
draft: false
prev:
  title: Изобретая protobuf
  url: 2026/develop-protobuf
---

Хотя `grpc` тесно ассоциирован с `protobuf` как часть одного фреймворка, эта связь не настолько сильная, чтобы на месте `protobuf` нельзя было использовать `msgpack`, упомянутый в прошлой статье `avro` или даже `json`. В отличие от `amqp`, протоколов `cassandra`, `kafka` и некоторых других систем, которые, на самом деле, объединяют в себе протоколы общения и сериализации, `grpc` как транспорт оборачивает сообщения, сериализованные в любом формате, в собственный бинарный протокол.

При этом и самостоятельным транспортом `grpc` назвать тоже трудно — он работает на `http/2`, используя в качестве тела запроса всего один бинарный фрейм, куда входят флаг, указывающий, сжато сообщение, например в `gzip`, или нет, размер сообщения и само сообщение. Ни больше ни меньше, `grpc` — это фреймворк, или, если быть точным, спецификация к фреймворку, позволяющая построить альтернативную классическому `http` экосистему на любом языке программирования. 

Хотя может показаться, что использование `http` протокола не является преимуществом по сравнению с привычным для многих `openapi`, важно понимать, что `http/2`, хоть и считается идейным продолжителем[^1], на самом деле является совсем другим протоколом.

Если не говорить про `http/1`, главный недостаток которого — закрытие соединения после каждого запроса — исправил `http/1.1`, даже он не смог избавиться от всех родовых травм этого протокола. И текстовый формат, если вы подумали про него, — не самая большая из них. В конце концов, есть текстовые протоколы, вроде `nats` и `redis`, по производительности не уступающие бинарным. Серьезной проблемой же является синхронность этого (`http/1.1`) протокола: нельзя отправить два запроса *параллельно*[^2] по одному соединению. Ради масштабирования приходится использовать пул соединений, который значительно дороже и ограниченнее мультиплексирования запросов через стримы, предлагаемых `http/2`. `grpc` не стал прятать `http/2`, а сделал его стримы — одно из главных преимуществ этого протокола — частью фреймворка, что доступно прямо в схеме определения сервисов. 

Чтобы понять преимущество стримов, надо знать, как работает `http/1.1`. Любой запрос внутри такого соединения блокирует целое соединение, пока на запрос не будет получен ответ. Так происходит из-за отсутствия какой-либо идентификации между запросами, что быстро их запутает, отправь мы следующий запрос, не дожидаясь ответа на предыдущий. Вернее, отправить следующий запрос мы можем, особенно если использовать [http/1.1 pipelining](https://en.wikipedia.org/wiki/HTTP_pipelining), — который, впрочем, не снискал популярности, — однако этот запрос будет обработан сервером только после завершения текущего. Как бы то ни было, мы сталкивались с проблемой [head of line blocking](https://en.wikipedia.org/wiki/Head-of-line_blocking), которую были вынуждены решать открытием нового соединения. 

Решением этой проблемы являются стримы, которые где-то, например в `amqp`, называют каналами, где-то, например в `cassandra`, сессиями, а где-то как-то еще. Идея у них общая: каждый стрим получает некоторый уникальный[^3] идентификатор, который добавляется к каждому запросу внутри этого стрима. Все запросы внутри стрима упорядочены, как если бы это было классическое `http/1` соединение, но между стримами соблюдать порядок нет необходимости, потому что и клиент, и сервер сопоставляют запрос с ответом, используя идентификаторы стрима. Когда эти идентификаторы заканчиваются, то есть их, стримов, количество превысило число 2^31, соединение открывается заново. Хотя это число является большим, только половину, а именно — нечетную, можно использовать для обычных запросов. Вторая, четная, половина нужна для реализации так называемого [server push](https://en.wikipedia.org/wiki/HTTP/2_Server_Push), о котором в этой статье я говорить не буду.

Стрим в `grpc` может быть использован как для унарных запросов, в случае с которыми стрим закрывается сразу после получения одного ответа от сервера, так и для потоковых запросов — тогда стрим может быть закрыт либо клиентом, либо сервером, либо любым из них в зависимости от типа стрима: клиентского, серверного или двунаправленного. Эти типы искусственно введены `grpc`, чтобы создать правильные ограничения при реализации определенных задач. По умолчанию же все `http/2` стримы являются двунаправленными.  

Важным дополнением в `http/2` являются трейлеры, которые имеют формат заголовков и отправляются после тела запроса. Поскольку стрим является продолжительным потоком сообщений, возникает необходимость каким-то образом его корректно завершить, передав окончательные статус выполнения и другую дополнительную информацию о состоянии стрима после его завершения. Раз заголовки были уже отправлены, нужен другой способ это сделать, и им являются трейлеры. Именно с помощью них `grpc` сервер отправляет заголовки `grpc-status` и `grpc-message` по окончании стрима.

Хотя `grpc` использует `http/2`, это проявляется не во всем. Так, в качестве статус-кода сервер всегда отправляет 200. Исключением является только единственный случай: если клиент в качестве `content-type` присылает что угодно, кроме `application/grpc`, сервер обязан вернуть 415-й код, потому что маловероятно, что специфические для `grpc` трейлеры клиент, приславший другой `content-type`, поймет. Все данные передаются только в теле запроса, включая различные идентификаторы, которые в обычном случае принято передавать в виде `path` параметров, и поэтому все запросы отправляются методом `POST`. Впрочем, на эти свойства вы все равно повлиять не можете: для вас все выглядит так, будто `grpc` использует собственный протокол общения. 

Чтобы договориться с сервером о формате сериализации входящих сообщений, клиент может добавить в заголовок `content-type` название формата через знак "`+`". Для `protobuf` заголовком будет `application/grpc+proto`. По умолчанию, как вы понимаете, и так будет `protobuf`, поэтому его передачу можно опустить. Если формат сериализации сервером не поддерживается, в качестве `grpc-status` будет возвращен код 12 (`UNIMPLEMENTED`)[^4]. То же самое будет при вызове несуществующего `rpc`. К слову, полное название `rpc`, которое передается как `path` в `http` протоколе, формируется из названия пакета, сервиса и имени `rpc` внутри этого сервиса. Например, для такой схемы именем будет `/queue.api.v1.QueueService/CreateQueue`:
```proto
syntax = "proto3";

package queue.api.v1;

service QueueService {
  rpc CreateQueue(...) returns (...);
}
```

Если имя пакета не указано, оно просто не используется. 

Поскольку каждое сообщение сериализуется в бинарный формат, в качестве которого обычно используется `protobuf`, оно хорошо поддается сжатию. Однако типичный для такой задачи заголовок `content-encoding` использовать нельзя, потому что он указывает на сериализацию всего тела сообщения, даже если оно отправляется частями, которое можно разжать только после полного его прочтения, в то время как в `grpc` каждое сообщение сжимается отдельно, о чем [говорит](https://github.com/thesis-php/grpc/blob/0.1.x/src/Internal/Protocol/Frame.php#L29) первый байт фрейма. Поэтому в `grpc` для передачи алгоритмов сжатия используются заголовки `grpc-encoding`, отправляемый клиентом, и `grpc-accept-encoding`, отправляемый сервером. Несмотря на отправку заголовка `grpc-encoding`, сообщение по-прежнему может быть не сжато, о чем свидетельствует упомянутый байт сжатия. 

Хотя обычно клиент заранее знает алгоритмы сжатия, поддерживаемые сервером, поскольку они часто являются частью одного приложения, иногда клиент может выяснить алгоритмы после отправки первого сообщения, получив заголовок `grpc-accept-encoding`, чтобы все следующие сообщения отправлять уже сжатыми, именно поэтому байт сжатия устанавливается на уровне каждого сообщения, что позволяет адаптировать настройки стрима уже после его создания. Для унарных запросов это неактуально, потому что после получения ответа сжимать уже нечего.

Кроме `grpc-status` и `grpc-message` трейлеров, которые в ряде случаев неспособны передать весь контекст ошибок, `grpc` вводит трейлер `grpc-status-details-bin`, значением которого должно быть сообщение [google.rpc.Status](https://github.com/googleapis/googleapis/blob/master/google/rpc/status.proto), закодированное в `base64` (как и любые заголовки и трейлеры с суффиксом `-bin`). Кажется, это единственный стандартный трейлер или заголовок, явно требующий передачи `protobuf` сообщения.

Поскольку `google.rpc.Status` требует передачи деталей ошибки в виде [google.protobuf.Any](https://github.com/protocolbuffers/protobuf/blob/main/src/google/protobuf/any.proto#L72), нам необходим реестр всех типов, используемых приложением. Хотя часто это будут сообщения из этой [схемы](https://github.com/googleapis/googleapis/blob/master/google/rpc/error_details.proto), использовать свои сообщения об ошибках тоже можно. Как сделать такой реестр и зачем он нужен `google.protobuf.Any`, я напишу в следующей, заключительной, статье. 

В нашей реализации [grpc](https://github.com/thesis-php/grpc) сервер может вернуть детали ошибки, бросив исключение:

```php
use Amp\Cancellation;
use Auth\Api\V1\AuthenticateRequest;
use Auth\Api\V1\AuthenticateResponse;
use Auth\Api\V1\AuthenticationServiceServer;
use Google\Rpc\Code;
use Google\Rpc\PreconditionFailure;
use Thesis\Grpc\InvokeError;
use Thesis\Grpc\Metadata;

/**
 * @api
 */
final readonly class AuthenticationServer implements AuthenticationServiceServer
{
    #[\Override]
    public function authenticate(AuthenticateRequest $request, Metadata $md, Cancellation $cancellation): AuthenticateResponse
    {
        ...

        throw new InvokeError(Code::FAILED_PRECONDITION, 'Invalid authentication credentials', [
            new PreconditionFailure([
                new PreconditionFailure\Violation('auth', 'credentials', 'invalid credentials'),
            ]),
        ]);
    }
}
```

А клиент — его поймав:
```php
use Amp\Cancellation;
use Auth\Api\V1\AuthenticateRequest;
use Google\Rpc\PreconditionFailure;
use Thesis\Grpc\InvokeError;

try {
   $response = $client->authenticate(new AuthenticateRequest(...));
} catch (InvokeError $e) {
   foreach ($e->details as $detail) {
      if ($detail instanceof PreconditionFailure) {}
   }
}
```

Чтобы клиент смог сообщить серверу, как долго он готов ждать ответ, можно передать заголовок [grpc-timeout](https://github.com/thesis-php/grpc/blob/0.1.x/src/Metadata/Timeout.php), используя как самое маленькое значение, которым будут наносекунды, так и самое большое — часы. Пожалуй, среди полезных пользователю `grpc` заголовков или трейлеров это был последний.

Чтобы построить `grpc` экосистему, мы, поскольку и так уже связали свою деятельность с [amphp](https://github.com/amphp), недолго думая, — о чем потом немного пожалели, — взяли за основу для клиента и сервера [amphp/http-client](https://github.com/amphp/http-client) и [amphp/http-server](https://github.com/amphp/http-server) соответственно. Сервер по умолчанию, как оно и должно быть, сам умеет обрабатывать входящие соединения по нужному протоколу, версию которого ему передает клиент, поэтому с его, клиентской, стороны версию понадобится передать явно:
```php
use Amp\Http\Client\Request;

$request = new Request(
  uri: '/queue.api.v1.QueueService/CreateQueue',
  method: 'POST',
  body: ...,
);

$request->setProtocolVersions(['2']);

$response = $this->client->request($request, $cancellation);
```

Хотя благодаря файберам неблокирующий запрос можно отправить без дополнительных ключевых слов, например `yield`, как было раньше, или функций, например `async`, как стало сейчас, в таком варианте он, хоть и не заблокирует поток выполнения, «заблокирует» вызывающий код, пока `grpc` сервер не пришлет ответ полностью, включая трейлеры, что нас точно не устраивает, раз мы собираемся использовать стримы. Ни в клиентском стриме, если мы планируем продолжительное время отправлять сообщения, мы не можем получить ответ от сервера сразу, ни в серверном, если планируем продолжительное время читать от него сообщения. Что уж говорить о двунаправленном — тут ситуация еще сложнее.

Я бы не хотел сгущать краски, но добавить [цвета](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) все равно придется:

```php
use function Amp\async;

$response = async($this->client->request(...), $request, $cancellation);
```

Между прочим, еще совсем недавно даже этот код не [работал](https://github.com/amphp/http-client/pull/380). Именно по этой (в большей степени) причине мы начали сомневаться в выборе библиотеки. Неужели люди, писавшие реализацию `http/2`, а уж тем более файберы, не понимают, как пользоваться стримами или, если понимают, как дать им интерфейс? В общем, выбора у нас все равно не было: неблокирующие `http` клиенты на дороге не валяются, особенно с реализацией протокола `http/2`, по крайней мере в `php`. Найдется время — напишем свой.

Итак, чтобы создать двунаправленный стрим, нужны две очереди: одна превращается в тело запроса, другая — тело ответа. Для этого можно использовать [amphp/pipeline](https://github.com/amphp/pipeline), который превращает обычные итераторы в конкурентные, а для превращения тела запроса из итератора в стрим, понятный клиенту, использовать [StreamedContent](https://github.com/amphp/http-client/blob/5.x/src/StreamedContent.php):
```php
use Amp\Pipeline;

/** @var Pipeline\Queue<In> $send */
$send = new Pipeline\Queue();

$request = new Request(
    uri: '/queue.api.v1.QueueService/CreateQueue',
    method: 'POST',
    body: StreamedContent::fromStream(
      new ReadableIterableStream($send->iterate()),
    ),
);
```

Осталось отправить *асинхронно* запрос и вернуть пользователю [стрим](https://github.com/thesis-php/grpc/blob/0.1.x/src/Client/Internal/Http2/ConcurrentClientStream.php):
```php
$response = async($this->client->request(...), $request, $cancellation);

return new ConcurrentClientStream($send);
```

Когда пользователь будет отправлять сообщения в стрим с помощью `ConcurrentClientStream::send()`, они из очереди попадут клиенту, который по мере возможности отправит их серверу. Правда, сейчас сообщения стрима никак не сериализуются и не сжимаются, поэтому из одной очереди мы можем сделать другую, пропуская элементы через [StreamCodec](https://github.com/thesis-php/grpc/blob/0.1.x/src/Internal/Http2/StreamCodec.php):
```php
$request = new Request(
    ...
    body: StreamedContent::fromStream(
      new ReadableIterableStream($this->codec->encode($send->iterate())),
    ),
);
```

---

[^1]: под продолжением идей я подразумеваю передачу метода, пути, заголовков и тела сообщения. 

[^2]: тут долго можно спорить, что называть параллелизмом при работе с сетью, потому что в конечном итоге все упирается в строго упорядоченный `tcp`, проблемы которого уже решает [quic](https://en.wikipedia.org/wiki/QUIC), построенный на базе `udp` и лежащий в основе `http/3`. Я же больше подразумеваю параллелизм на стороне приложения, а не протокола общения, строгая упорядоченность которого мешает реализации этого вида параллелизма. Иными словами, приложение, использующее `http/2`, способно только с одним соединением принимать или отправлять несколько запросов одновременно, в то время как `http/1.1` требует открыть другое соединение, если необходимо отправить следующий запрос немедленно. 

[^3]: в некоторых протоколах, например в `amqp`, уникальный он только на то время, пока о нем не забыли клиент с сервером; после этого ранее использованные идентификаторы можно использовать опять.

[^4]: этот и другой коды берутся из [этого енама](https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto#L32). Если вы обратите внимание, в комментариях к каждому коду описан соответствующий `http` код, от чего может сложиться впечатление, что они всегда отправляются в паре. Однако это не так: `http` код отправляется только при загадочном (особенно при использовании прокси) отсутствии заголовка `grpc-status`, и поэтому клиент может использовать классический заголовок в качестве замены.
